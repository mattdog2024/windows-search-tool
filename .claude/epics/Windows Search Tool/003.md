---
name: SQLite FTS5 数据库实现
status: open
created: 2025-10-16T08:21:20Z
updated: 2025-10-16T08:21:20Z
github: Will be updated when synced to GitHub
depends_on: [001]
parallel: true
conflicts_with: []
---

# Task: SQLite FTS5 数据库实现

## Description

实现基于 SQLite FTS5 的全文搜索数据库,包括数据库模式设计、DBManager 类实现、性能优化配置和批量操作支持。FTS5 提供了强大的全文搜索能力和 BM25 相关度排序,是本项目搜索功能的核心。

**核心目标:**
- 设计完整的数据库模式(documents, documents_fts, metadata, summaries)
- 实现 DBManager 类提供 CRUD 操作
- 配置 FTS5 性能优化(WAL, cache_size, page_size)
- 实现批量插入和事务管理
- 提供索引统计功能

## Acceptance Criteria

- [ ] 数据库模式设计完成
  - **documents 表** - 文档主表
    - id (INTEGER PRIMARY KEY)
    - file_path (TEXT UNIQUE)
    - file_name (TEXT)
    - file_size (INTEGER)
    - file_type (TEXT)
    - content_hash (TEXT)
    - created_at, modified_at, indexed_at (DATETIME)
    - status (TEXT: active/deleted/error)

  - **documents_fts 表** - FTS5 全文搜索表
    - content (全文索引字段)
    - content_rowid 链接到 documents.id
    - 分词器配置: porter unicode61 remove_diacritics

  - **document_metadata 表** - 文档元数据(键值对)
    - id, document_id, key, value
    - FOREIGN KEY 到 documents

  - **document_summaries 表** - AI 生成的摘要
    - id, document_id, summary, entities, generated_at
    - FOREIGN KEY 到 documents

  - **index_config 表** - 索引配置
    - key, value (键值对存储)

- [ ] 性能优化索引创建
  - idx_documents_file_path
  - idx_documents_file_type
  - idx_documents_modified_at
  - idx_documents_status
  - idx_metadata_document_id
  - idx_metadata_key

- [ ] DBManager 类实现
  - 数据库连接管理(连接池)
  - 初始化数据库模式
  - CRUD 操作(insert, update, delete, select)
  - 批量插入优化(事务批量提交)
  - 全文搜索接口
  - 统计信息查询

- [ ] 性能优化配置
  - PRAGMA journal_mode=WAL (提高并发性能)
  - PRAGMA synchronous=NORMAL (平衡性能和安全)
  - PRAGMA cache_size=-64000 (64MB 缓存)
  - PRAGMA temp_store=MEMORY (内存临时存储)
  - PRAGMA mmap_size=268435456 (256MB 内存映射)

- [ ] 批量操作支持
  - batch_insert_documents(批量插入文档)
  - 事务管理(begin, commit, rollback)
  - 批次大小: 100 条记录

- [ ] 数据库工具函数
  - vacuum() - 数据库压缩
  - get_statistics() - 获取统计信息
  - backup(path) - 数据库备份
  - check_integrity() - 完整性检查

- [ ] 单元测试
  - 数据库创建测试
  - CRUD 操作测试
  - 批量插入性能测试
  - FTS 搜索功能测试
  - 代码覆盖率 ≥ 90%

## Technical Details

### 数据库模式

```sql
-- 文档主表
CREATE TABLE documents (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    file_path TEXT NOT NULL UNIQUE,
    file_name TEXT NOT NULL,
    file_size INTEGER,
    file_type TEXT,
    content_hash TEXT,
    created_at DATETIME,
    modified_at DATETIME,
    indexed_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    status TEXT DEFAULT 'active'
);

-- FTS5 全文搜索表
CREATE VIRTUAL TABLE documents_fts USING fts5(
    content,
    content_rowid=id,
    tokenize='porter unicode61 remove_diacritics 2'
);

-- 文档元数据表
CREATE TABLE document_metadata (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    document_id INTEGER NOT NULL,
    key TEXT NOT NULL,
    value TEXT,
    FOREIGN KEY(document_id) REFERENCES documents(id) ON DELETE CASCADE,
    UNIQUE(document_id, key)
);

-- AI 摘要表
CREATE TABLE document_summaries (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    document_id INTEGER NOT NULL UNIQUE,
    summary TEXT,
    key_points TEXT,
    entities TEXT,
    generated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY(document_id) REFERENCES documents(id) ON DELETE CASCADE
);

-- 索引配置表
CREATE TABLE index_config (
    key TEXT PRIMARY KEY,
    value TEXT
);

-- 性能优化索引
CREATE INDEX idx_documents_file_path ON documents(file_path);
CREATE INDEX idx_documents_file_type ON documents(file_type);
CREATE INDEX idx_documents_modified_at ON documents(modified_at);
CREATE INDEX idx_documents_status ON documents(status);
CREATE INDEX idx_metadata_document_id ON document_metadata(document_id);
CREATE INDEX idx_metadata_key ON document_metadata(key);
```

### DBManager 类

```python
# src/data/db_manager.py
import sqlite3
from contextlib import contextmanager
from typing import List, Dict, Any, Optional
from datetime import datetime
import logging

logger = logging.getLogger(__name__)

class DBManager:
    """SQLite 数据库管理器"""

    def __init__(self, db_path: str):
        self.db_path = db_path
        self.connection = None
        self._init_database()

    def _init_database(self):
        """初始化数据库"""
        self.connection = sqlite3.connect(
            self.db_path,
            check_same_thread=False
        )
        self.connection.row_factory = sqlite3.Row

        # 性能优化配置
        self._configure_performance()

        # 创建数据库模式
        self._create_schema()

    def _configure_performance(self):
        """配置性能优化参数"""
        cursor = self.connection.cursor()
        cursor.execute("PRAGMA journal_mode=WAL")
        cursor.execute("PRAGMA synchronous=NORMAL")
        cursor.execute("PRAGMA cache_size=-64000")  # 64MB
        cursor.execute("PRAGMA temp_store=MEMORY")
        cursor.execute("PRAGMA mmap_size=268435456")  # 256MB
        self.connection.commit()

    def _create_schema(self):
        """创建数据库模式"""
        cursor = self.connection.cursor()

        # 文档主表
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS documents (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                file_path TEXT NOT NULL UNIQUE,
                file_name TEXT NOT NULL,
                file_size INTEGER,
                file_type TEXT,
                content_hash TEXT,
                created_at DATETIME,
                modified_at DATETIME,
                indexed_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                status TEXT DEFAULT 'active'
            )
        """)

        # FTS5 全文搜索表
        cursor.execute("""
            CREATE VIRTUAL TABLE IF NOT EXISTS documents_fts USING fts5(
                content,
                content_rowid=id,
                tokenize='porter unicode61 remove_diacritics 2'
            )
        """)

        # 元数据表
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS document_metadata (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                document_id INTEGER NOT NULL,
                key TEXT NOT NULL,
                value TEXT,
                FOREIGN KEY(document_id) REFERENCES documents(id) ON DELETE CASCADE,
                UNIQUE(document_id, key)
            )
        """)

        # AI 摘要表
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS document_summaries (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                document_id INTEGER NOT NULL UNIQUE,
                summary TEXT,
                key_points TEXT,
                entities TEXT,
                generated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY(document_id) REFERENCES documents(id) ON DELETE CASCADE
            )
        """)

        # 索引配置表
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS index_config (
                key TEXT PRIMARY KEY,
                value TEXT
            )
        """)

        # 创建索引
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_documents_file_path ON documents(file_path)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_documents_file_type ON documents(file_type)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_documents_modified_at ON documents(modified_at)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_documents_status ON documents(status)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_metadata_document_id ON document_metadata(document_id)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_metadata_key ON document_metadata(key)")

        self.connection.commit()

    @contextmanager
    def transaction(self):
        """事务上下文管理器"""
        cursor = self.connection.cursor()
        try:
            yield cursor
            self.connection.commit()
        except Exception as e:
            self.connection.rollback()
            logger.error(f"Transaction failed: {e}")
            raise

    def insert_document(self, document: Dict[str, Any]) -> int:
        """插入单个文档"""
        with self.transaction() as cursor:
            cursor.execute("""
                INSERT INTO documents (file_path, file_name, file_size, file_type,
                                      content_hash, created_at, modified_at)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            """, (
                document['file_path'],
                document['file_name'],
                document['file_size'],
                document['file_type'],
                document['content_hash'],
                document['created_at'],
                document['modified_at']
            ))

            doc_id = cursor.lastrowid

            # 插入内容到 FTS 表
            cursor.execute("""
                INSERT INTO documents_fts (rowid, content)
                VALUES (?, ?)
            """, (doc_id, document['content']))

            # 插入元数据
            if 'metadata' in document:
                for key, value in document['metadata'].items():
                    cursor.execute("""
                        INSERT INTO document_metadata (document_id, key, value)
                        VALUES (?, ?, ?)
                    """, (doc_id, key, str(value)))

            return doc_id

    def batch_insert_documents(self, documents: List[Dict[str, Any]]) -> List[int]:
        """批量插入文档"""
        doc_ids = []
        with self.transaction() as cursor:
            for doc in documents:
                # 插入主记录
                cursor.execute("""
                    INSERT INTO documents (file_path, file_name, file_size, file_type,
                                          content_hash, created_at, modified_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                """, (
                    doc['file_path'],
                    doc['file_name'],
                    doc['file_size'],
                    doc['file_type'],
                    doc['content_hash'],
                    doc['created_at'],
                    doc['modified_at']
                ))

                doc_id = cursor.lastrowid
                doc_ids.append(doc_id)

                # 插入 FTS 内容
                cursor.execute("""
                    INSERT INTO documents_fts (rowid, content)
                    VALUES (?, ?)
                """, (doc_id, doc['content']))

                # 插入元数据
                if 'metadata' in doc:
                    for key, value in doc['metadata'].items():
                        cursor.execute("""
                            INSERT INTO document_metadata (document_id, key, value)
                            VALUES (?, ?, ?)
                        """, (doc_id, key, str(value)))

        return doc_ids

    def search_fts(self, query: str, limit: int = 20, offset: int = 0) -> List[Dict[str, Any]]:
        """全文搜索"""
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT
                d.id,
                d.file_path,
                d.file_name,
                d.file_type,
                d.modified_at,
                snippet(documents_fts, -1, '<mark>', '</mark>', '...', 64) as snippet,
                rank
            FROM documents_fts
            JOIN documents d ON documents_fts.rowid = d.id
            WHERE documents_fts MATCH ?
            ORDER BY rank
            LIMIT ? OFFSET ?
        """, (query, limit, offset))

        results = []
        for row in cursor.fetchall():
            results.append(dict(row))
        return results

    def get_statistics(self) -> Dict[str, Any]:
        """获取统计信息"""
        cursor = self.connection.cursor()

        # 文档数量
        cursor.execute("SELECT COUNT(*) as count FROM documents WHERE status='active'")
        doc_count = cursor.fetchone()['count']

        # 总大小
        cursor.execute("SELECT SUM(file_size) as total_size FROM documents WHERE status='active'")
        total_size = cursor.fetchone()['total_size'] or 0

        # 最后更新时间
        cursor.execute("SELECT MAX(indexed_at) as last_update FROM documents")
        last_update = cursor.fetchone()['last_update']

        # 文件类型分布
        cursor.execute("""
            SELECT file_type, COUNT(*) as count
            FROM documents
            WHERE status='active'
            GROUP BY file_type
        """)
        file_types = {row['file_type']: row['count'] for row in cursor.fetchall()}

        return {
            'document_count': doc_count,
            'total_size': total_size,
            'last_update': last_update,
            'file_types': file_types
        }

    def close(self):
        """关闭数据库连接"""
        if self.connection:
            self.connection.close()
```

## Dependencies

**外部依赖:**
- Python 3.11+ (内置 sqlite3 模块,支持 FTS5)

**内部依赖:**
- Task 001: 项目基础架构(日志系统)

## Effort Estimate

- **Size:** M (Medium)
- **Hours:** 12-16 小时
- **Parallel:** true (可与 Task 002 并行)

**时间分配:**
- 数据库模式设计: 3 小时
- DBManager 类实现: 5 小时
- 性能优化配置: 2 小时
- 单元测试编写: 4 小时
- 文档和调试: 2 小时

## Definition of Done

- [x] 代码实现完成
  - 数据库模式完整创建
  - DBManager 类实现所有 CRUD 操作
  - 批量插入优化实现
  - FTS5 搜索接口实现

- [x] 测试完成
  - 数据库创建测试
  - 插入/更新/删除操作测试
  - 批量插入性能测试(≥ 100 条/秒)
  - FTS 搜索准确性测试
  - 代码覆盖率 ≥ 90%

- [x] 文档完成
  - 数据库模式文档
  - API 使用示例

- [x] 代码质量
  - 通过 black 格式化
  - 通过 pylint 检查(评分 ≥ 8.0)
  - 类型注解完整

- [x] 验收测试
  - 能创建和初始化数据库
  - 批量插入 1000 条记录 < 10 秒
  - FTS 搜索返回正确结果
  - 统计信息准确
